{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDfbL3w_Z0Od",
        "outputId": "7532966e-1c4a-4641-c928-4cda14c53389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "# def get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "#   train_dataset = datasets.STL10('./data', split='train', download=download,\n",
        "#                                   transform=transforms.ToTensor())\n",
        "\n",
        "#   train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "#                             num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "#   test_dataset = datasets.STL10('./data', split='test', download=download,\n",
        "#                                   transform=transforms.ToTensor())\n",
        "\n",
        "#   test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "#                             num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "#   return train_loader, test_loader\n",
        "\n",
        "# def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "#   train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
        "#                                   transform=transforms.ToTensor())\n",
        "\n",
        "#   train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "#                             num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "#   test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
        "#                                   transform=transforms.ToTensor())\n",
        "\n",
        "#   test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "#                             num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "#   return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "def get_balanced_sampler(dataset):\n",
        "    # Count the number of images per class\n",
        "    class_counts = [0] * 7  # Assuming 4 classes\n",
        "    for _, label in dataset:\n",
        "        class_counts[label] += 1\n",
        "\n",
        "    # Weight for each sample\n",
        "    weights = [1.0 / class_counts[label] for _, label in dataset]\n",
        "    sampler = WeightedRandomSampler(weights, num_samples=7000, replacement=True)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "def get_balanced_data_loader(data_dir, batch_size=256, num_workers=0):\n",
        "    # Define transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Load the dataset with transformations\n",
        "    train_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "    # Create a balanced sampler\n",
        "    sampler = get_balanced_sampler(train_dataset)\n",
        "\n",
        "    # Create the DataLoader with the sampler\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=num_workers)\n",
        "\n",
        "    return train_loader\n",
        "\n",
        "# Call the function with your dataset directory\n",
        "train_loader = get_balanced_data_loader('/home/paritosh/workspace/IK_contrastive_dataset/synthetic_superhard', batch_size=128, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_loader, test_loader = get_custom_data_loaders(data_dir='/path/to/your/dataset', batch_size=64, shuffle=True, num_workers=4)\n",
        "# train_loader = get_custom_data_loaders(data_dir='/home/paritosh/workspace/TabularDeath/contrastive_dataset', batch_size=1024, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6N8lYkbmDTaK"
      },
      "outputs": [],
      "source": [
        "# with open(os.path.join('./config.yml')) as file:\n",
        "#   config = yaml.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a18lPD-tIle6"
      },
      "outputs": [],
      "source": [
        "# if config.arch == 'resnet18':\n",
        "#   model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
        "# elif config.arch == 'resnet50':\n",
        "#   model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torchvision.models as models\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Adjust this path to where your trained model's weights are saved\n",
        "# # model_path = 'path/to/your/trained_model.pth'\n",
        "# model_path = 'D:\\_workspace\\ISRO_SimCLR\\Custom_SimCLR\\runs\\test_run1\\checkpoint_0005.pth.tar'\n",
        "\n",
        "# # Load the model (assuming it's a ResNet18 trained with SimCLR)\n",
        "# model = models.resnet18(pretrained=False)\n",
        "# model.fc = torch.nn.Linear(model.fc.in_features, 4)  # Adjust for 4 classes\n",
        "\n",
        "# # Modify the first layer to accept grayscale images\n",
        "# model.conv1 = torch.nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size,\n",
        "#                               stride=model.conv1.stride, padding=model.conv1.padding, bias=False)\n",
        "\n",
        "# # Load the trained weights\n",
        "# model.load_state_dict(torch.load(model_path))\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torchvision.models as models\n",
        "\n",
        "# model_path = 'D:\\\\_workspace\\\\ISRO_SimCLR\\\\Custom_SimCLR\\\\runs\\\\test_run1\\\\checkpoint_0005.pth.tar'\n",
        "\n",
        "# # Load the checkpoint\n",
        "# checkpoint = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "# # Extract the state dictionary and remove 'backbone.' prefix from each key\n",
        "# state_dict = {k.replace(\"backbone.\", \"\"): v for k, v in checkpoint['state_dict'].items()}\n",
        "\n",
        "# # Load the model (assuming it's a ResNet18 trained with SimCLR)\n",
        "# model = models.resnet18(pretrained=False)\n",
        "\n",
        "# # Modify the first layer to accept grayscale images\n",
        "# model.conv1 = torch.nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size,\n",
        "#                               stride=model.conv1.stride, padding=model.conv1.padding, bias=False)\n",
        "\n",
        "# # Replace the fully connected layer for 4 classes\n",
        "# model.fc = torch.nn.Linear(model.fc.in_features, 4)\n",
        "\n",
        "# # Load the trained weights into the model\n",
        "# model.load_state_dict(state_dict)\n",
        "\n",
        "# # Move model to the appropriate device (GPU or CPU)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "# checkpoint = torch.load('checkpoint_0040.pth.tar', map_location=device)\n",
        "checkpoint = torch.load('/home/paritosh/workspace/TabularDeath_saved_models/ResNet-101/Mar18_06-33-27_gpu021/checkpoint_0300.pth.tar', map_location=device)\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "for k in list(state_dict.keys()):\n",
        "\n",
        "  if k.startswith('backbone.'):\n",
        "    if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "      # remove prefix\n",
        "      state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "  del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/paritosh/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/paritosh/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        " # Load the model (assuming it's a ResNet18 trained with SimCLR)\n",
        "model = torchvision.models.resnet101(pretrained=False, num_classes=4).to(device)\n",
        "\n",
        "# Modify the first layer to accept grayscale images\n",
        "model.conv1 = torch.nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size,\n",
        "                              stride=model.conv1.stride, padding=model.conv1.padding, bias=False)\n",
        "\n",
        "# Move model to the appropriate device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (12): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (13): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (14): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (15): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (16): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (17): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (18): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (19): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (20): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (21): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (22): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modify the fully connected layer\n",
        "model.fc = torch.nn.Identity()\n",
        "\n",
        "# Now the model outputs the 512-dimensional embeddings from the AdaptiveAvgPool2d layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dtYqHZirMNZk"
      },
      "outputs": [],
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient computation\n",
        "with torch.no_grad():\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    for images, batch_labels in train_loader:\n",
        "        # Move images to the same device as the model\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass to get embeddings\n",
        "        batch_embeddings = model(images)\n",
        "\n",
        "        # Store embeddings and labels\n",
        "        embeddings.append(batch_embeddings.cpu().numpy())\n",
        "        labels.append(batch_labels.numpy())\n",
        "\n",
        "# Concatenate all collected embeddings and labels\n",
        "embeddings = np.concatenate(embeddings, axis=0)\n",
        "labels = np.concatenate(labels, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7000, 2048)\n",
            "(7000,)\n"
          ]
        }
      ],
      "source": [
        "print(embeddings.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 7000 samples in 0.004s...\n",
            "[t-SNE] Computed neighbors for 7000 samples in 1.252s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 7000\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 7000\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 7000\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 7000\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 7000\n",
            "[t-SNE] Computed conditional probabilities for sample 6000 / 7000\n",
            "[t-SNE] Computed conditional probabilities for sample 7000 / 7000\n",
            "[t-SNE] Mean sigma: 2.896597\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 88.056923\n",
            "[t-SNE] KL divergence after 1000 iterations: 1.954591\n"
          ]
        }
      ],
      "source": [
        "# project embeddings into 2D space\n",
        "# from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# pca = PCA(n_components=2)\n",
        "# pca.fit(embeddings)\n",
        "# pca_embeddings = pca.transform(embeddings)\n",
        "\n",
        "tsne = TSNE(n_components=2, verbose=1)\n",
        "tsne_embeddings = tsne.fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "VAT Processing: 100%|██████████| 6997/6997 [06:48<00:00, 17.14it/s] \n",
            "Final loop: 100%|██████████| 7000/7000 [00:00<00:00, 6839070.11it/s]\n",
            "iVAT Processing: 100%|██████████| 6999/6999 [00:00<00:00, 17029.77it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from VAT_library.iVAT import iVAT\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# pairwise_dist = cdist(embeddings, embeddings)\n",
        "# pairwise_dist = cdist(pca_embeddings, pca_embeddings)\n",
        "pairwise_dist = cdist(tsne_embeddings, tsne_embeddings)\n",
        "\n",
        "RiV, RV, reordering_mat = iVAT(pairwise_dist)\n",
        "\n",
        "plt.imshow(RiV, cmap='gray')\n",
        "save_path = \"/home/paritosh/workspace/TabularDeath_saved_models/ResNet-101/Mar18_06-33-27_gpu021/synthetic_superhard_2D.png\"  # Specify the path and file name here\n",
        "plt.savefig(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.utils import resample\n",
        "\n",
        "# # Load the original dataset from the CSV file\n",
        "# data = pd.read_csv('/home/paritosh/workspace/TabularDeath/synthetic_hard_data.csv')\n",
        "\n",
        "# # Assuming 'target' is the column name for labels\n",
        "# X = data.drop('label', axis=1)\n",
        "# y = data['label']\n",
        "\n",
        "# # Determine the number of samples per class\n",
        "# samples_per_class = 14000 // 7  # Integer division to ensure equal number of samples per class\n",
        "\n",
        "# sampled_dfs = []\n",
        "\n",
        "# # Iterate over each unique class label\n",
        "# for label in y.unique():\n",
        "#     # Get the data points belonging to the current class\n",
        "#     class_data = data[y == label]\n",
        "    \n",
        "#     # Sample the desired number of data points from the current class with replacement\n",
        "#     sampled_class_data = resample(class_data, n_samples=samples_per_class, replace=True, random_state=42)\n",
        "    \n",
        "#     # Append the sampled data points to the sampled_data DataFrame\n",
        "#     sampled_dfs.append(sampled_class_data)\n",
        "\n",
        "# sampled_data = pd.concat(sampled_dfs, ignore_index=True)\n",
        "\n",
        "# # Separate the features (X) and labels (y) from the sampled data\n",
        "# sampled_X = sampled_data.drop('label', axis=1)\n",
        "# sampled_y = sampled_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(sampled_X.shape)\n",
        "\n",
        "# pairwise_dist = cdist(sampled_X, sampled_X)\n",
        "\n",
        "# RiV, RV, reordering_mat = iVAT(pairwise_dist)\n",
        "\n",
        "# plt.imshow(RiV, cmap='gray')\n",
        "# save_path = \"/home/paritosh/workspace/IK_contrastive_dataset/synthetic_hard/synthetic_hard_raw.png\"\n",
        "# plt.savefig(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tsne = TSNE(n_components=2, verbose=1)\n",
        "# tsne_embeddings = tsne.fit_transform(sampled_X)\n",
        "\n",
        "# pairwise_dist = cdist(tsne_embeddings, tsne_embeddings)\n",
        "\n",
        "# RiV, RV, reordering_mat = iVAT(pairwise_dist)\n",
        "\n",
        "# plt.imshow(RiV, cmap='gray')\n",
        "# save_path = \"/home/paritosh/workspace/IK_contrastive_dataset/synthetic_hard/synthetic_hard_raw_2D.png\"\n",
        "# plt.savefig(save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "​",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
